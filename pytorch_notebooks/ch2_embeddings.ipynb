{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ['impossible', 'mr', 'bennet', 'impossible', 'when', 'i', 'am', 'not', 'acquainted', 'with', 'him']\n",
      "Sentence length: 11\n"
     ]
    }
   ],
   "source": [
    "word2index_dict = {\n",
    "    \"impossible\": 3394,\n",
    "    \"mr\": 4305,\n",
    "    \"bennet\": 813,\n",
    "    \"when\": 7078,\n",
    "    \"i\": 3315,\n",
    "    \"am\": 415,\n",
    "    \"not\": 4436,\n",
    "    \"acquainted\": 239,\n",
    "    \"with\": 7148,\n",
    "    \"him\": 3215\n",
    "}\n",
    "sentence = \"impossible mr bennet impossible when i am not acquainted with him\".split()\n",
    "vocab_size = 7261\n",
    "sentence_length = len(sentence)\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Sentence length:\", sentence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 3394 impossible\n",
      " 1 4305 mr\n",
      " 2  813 bennet\n",
      " 3 3394 impossible\n",
      " 4 7078 when\n",
      " 5 3315 i\n",
      " 6  415 am\n",
      " 7 4436 not\n",
      " 8  239 acquainted\n",
      " 9 7148 with\n",
      "10 3215 him\n",
      "One-hot encoded tensor shape: torch.Size([11, 7261])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize a 2D tensor of zeros with shape (sentence_length, vocab_size).\n",
    "# Each row in this tensor will hold the one-hot representation of a word.\n",
    "word_tensor = torch.zeros(sentence_length, vocab_size)\n",
    "\n",
    "# Loop through the words to build their one-hot vectors.\n",
    "for i, word in enumerate(sentence):\n",
    "    # Retrieve the numeric index of the current word.\n",
    "    word_index = word2index_dict[word]\n",
    "    # Set the corresponding position in the tensor to 1 to mark this word.\n",
    "    word_tensor[i][word_index] = 1\n",
    "    # Print each word's index and related data for verification.\n",
    "    print(\"{:2d} {:4d} {}\".format(i, word_index, word))\n",
    "\n",
    "# Print the shape of the one-hot encoded tensor for confirmation.\n",
    "print(\"One-hot encoded tensor shape:\", word_tensor.shape)\n",
    "# One-hot encoding is used to represent words as sparse vectors \n",
    "# for further processing in NLP tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "'''\n",
    "print(r\"\"\"\n",
    "+------------------+         +-------------+       +----------------------+\n",
    "|   Input Words    |  -->    | Embedding   |  -->  | Dense Vectors (R^d) |\n",
    "+------------------+         |  Layer      |       +----------------------+\n",
    "                              \\___________/\n",
    "                              Each word index is\n",
    "                              mapped to a dense\n",
    "                              vector of dimension d\n",
    "\"\"\")\n",
    "'''\n",
    "# Instead of a 7261-dimensional one-hot vector, we use an embedding layer to map each word to a 100-dimensional vector.\n",
    "embedding_dim = 100\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "# Convert the sentence into a tensor of word indices\n",
    "word_indices = [word2index_dict[word] for word in sentence]\n",
    "word_indices_tensor = torch.tensor(word_indices, dtype=torch.long)\n",
    "print(\"\\nWord indices tensor:\", word_indices_tensor)\n",
    "# Get the dense 100-dimensional representation for each word\n",
    "embedded_sentence = embedding(word_indices_tensor)\n",
    "print(\"Embedded sentence shape:\", embedded_sentence.shape)\n",
    "# Expected: torch.Size([11, 100])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
